{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "816b401b-f3f0-4e54-85c5-c2d400920636",
   "metadata": {},
   "source": [
    "# Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c626ab5d-a8ca-4876-8948-ed20b9765d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deepchem torch-geometric transformers lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4630335e-2463-4e0e-91ac-e4082429eea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.dgl.ai/wheels/torch-2.3/cu121/repo.html\n",
      "Collecting dgl\n",
      "  Downloading https://data.dgl.ai/wheels/torch-2.3/cu121/dgl-2.4.0%2Bcu121-cp311-cp311-manylinux1_x86_64.whl (355.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.1/355.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /opt/conda/lib/python3.11/site-packages (from dgl) (3.3)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.11/site-packages (from dgl) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from dgl) (24.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from dgl) (2.2.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.11/site-packages (from dgl) (5.9.8)\n",
      "Collecting pydantic>=2.0 (from dgl)\n",
      "  Downloading pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from dgl) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from dgl) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from dgl) (1.13.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from dgl) (4.66.2)\n",
      "Requirement already satisfied: torch<=2.4.0 in /opt/conda/lib/python3.11/site-packages (from dgl) (2.3.1+cu121)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->dgl)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic>=2.0->dgl)\n",
      "  Downloading pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-extensions>=4.12.2 (from pydantic>=2.0->dgl)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.0->dgl)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (2024.2.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (3.13.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (1.12)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<=2.4.0->dgl) (12.5.40)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->dgl) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->dgl) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->dgl) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch<=2.4.0->dgl) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch<=2.4.0->dgl) (1.3.0)\n",
      "Downloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.6/443.6 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-extensions, annotated-types, typing-inspection, pydantic-core, pydantic, dgl\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "Successfully installed annotated-types-0.7.0 dgl-2.4.0+cu121 pydantic-2.11.3 pydantic-core-2.33.1 typing-extensions-4.13.2 typing-inspection-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install  dgl -f https://data.dgl.ai/wheels/torch-2.3/cu121/repo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94b18ebe-12ca-4481-8083-2406f3b64337",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39e3a67-52b6-4033-bba8-88302c0acec3",
   "metadata": {},
   "source": [
    "# QM9 DeepChem Dataset Info\n",
    "QM9_TASKS = [\n",
    "    \"mu\", \"alpha\", \"homo\", \"lumo\", \"gap\", \"r2\", \"zpve\", \"cv\", \"u0\", \"u298\",\n",
    "    \"h298\", \"g298\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed65a9c3-7d50-4220-9f0b-cac75881e770",
   "metadata": {},
   "source": [
    "# MolGraphConvFeaturizer Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "81691b57-7ff9-4637-bdfc-3cb9ef42e2c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "\n",
    "tasks, datasets, transformers = dc.molnet.load_qm9(featurizer=featurizer)\n",
    "\n",
    "train, val, test = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "81db4ca4-7ef9-4b1c-a4c9-de1014866e21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105576, 12)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b323a4a5-a13a-4467-8584-fc6061ad9cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphData(node_features=[9, 30], edge_index=[2, 18], edge_features=[18, 11])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.X[6] # 30, 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3097ca5e-453a-4fb9-adaf-e7781364a5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DiskDataset X.shape: (105576,), y.shape: (105576, 12), w.shape: (105576, 12), task_names: ['mu' 'alpha' 'homo' ... 'u298' 'h298' 'g298']>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0c6cb511-29cd-4f6d-977a-ee8ecdc30fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataset(dataset, selected_indicies):\n",
    "    X = dataset.X\n",
    "    y = dataset.y[:, selected_indicies]\n",
    "    w = dataset.w[:, selected_indicies]\n",
    "    ids = dataset.ids\n",
    "    return dc.data.NumpyDataset(X, y, w, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "547f0add-6961-4ff0-99bb-8d2bb362f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose only tasks= [\"homo\", \"lumo\", \"gap\"]\n",
    "from deepchem.trans import NormalizationTransformer\n",
    "\n",
    "\n",
    "\n",
    "selected_tasks = [\"homo\", \"lumo\", \"gap\"]\n",
    "selected_indicies = [tasks.index(task) for task in selected_tasks]\n",
    "\n",
    "train_filtered = filter_dataset(train, selected_indicies)\n",
    "val_filtered = filter_dataset(val, selected_indicies)\n",
    "test_filtered = filter_dataset(test, selected_indicies)\n",
    "\n",
    "transformers = [NormalizationTransformer(\n",
    "    transform_y=True,\n",
    "    dataset=train_filtered,\n",
    "    move_mean=True\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "638163b8-fc5e-4411-a1db-20dbce9a22e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphData(node_features=[16, 30], edge_index=[2, 32], edge_features=[32, 11])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filtered.X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5eaefd80-2cc6-4f7e-85af-6d813e47dda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe117b8-b69d-41d2-bb25-fec69d7070ae",
   "metadata": {},
   "source": [
    "## PagtnModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d67fb984-1156-4ff3-819d-ffe43869530d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dgllife\n",
      "  Downloading dgllife-0.3.2-py3-none-any.whl.metadata (667 bytes)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /opt/conda/lib/python3.11/site-packages (from dgllife) (1.4.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from dgllife) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.22.0 in /opt/conda/lib/python3.11/site-packages (from dgllife) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from dgllife) (4.66.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.11/site-packages (from dgllife) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from dgllife) (1.13.0)\n",
      "Requirement already satisfied: networkx>=2.1 in /opt/conda/lib/python3.11/site-packages (from dgllife) (3.3)\n",
      "Collecting hyperopt (from dgllife)\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from dgllife) (1.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.22.0->dgllife) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.22.0->dgllife) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.22.0->dgllife) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.22.0->dgllife) (2024.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=0.22.2->dgllife) (3.5.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from hyperopt->dgllife) (1.16.0)\n",
      "Collecting future (from hyperopt->dgllife)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.11/site-packages (from hyperopt->dgllife) (3.0.0)\n",
      "Collecting py4j (from hyperopt->dgllife)\n",
      "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->dgllife) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->dgllife) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->dgllife) (2024.1)\n",
      "Downloading dgllife-0.3.2-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.0/203.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: py4j, future, hyperopt, dgllife\n",
      "Successfully installed dgllife-0.3.2 future-1.0.0 hyperopt-0.2.7 py4j-0.10.9.9\n"
     ]
    }
   ],
   "source": [
    "!pip install dgllife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3ecfb494-823a-4a21-9950-6f74929e7680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from deepchem.models.optimizers import Adam\n",
    "# tasks = [ \"mu\", \"alpha\", \"homo\", \"lumo\", \"gap\", \"r2\", \"zpve\", \"cv\", \"u0\", \"u298\", \"h298\", \"g298\" ]  # Multiple tasks\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model = dc.models.PagtnModel(\n",
    "    n_tasks=len(selected_tasks),\n",
    "    number_atom_features=30, # Should match the dimension of featurized dataset\n",
    "    number_bond_features=11, # ''\n",
    "    mode='regression',\n",
    "    batch_size=16384,\n",
    "    # learning_rate=0.025,\n",
    "    optimizer = optimizer,\n",
    "    hidden_features=64,  # Hidden dimension size\n",
    "    output_node_features=64,  # Output features before final layer\n",
    "    num_layers=3,        # Number of PAGTN layers\n",
    "    num_heads=4,         # Number of attention heads\n",
    "    dropout=0.2,\n",
    "    max_path_length=5,   # Should match featurizer's max_length\n",
    "    path_hidden_dim=64, # Hidden dimension for path embeddings\n",
    "    device=device,\n",
    "    model_dir=\"./models/PagtnModel/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d292a84a-f0cd-43a8-94a3-b656d10970b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    dc.metrics.Metric(dc.metrics.mae_score),\n",
    "    dc.metrics.Metric(dc.metrics.pearson_r2_score),\n",
    "    dc.metrics.Metric(dc.metrics.mean_squared_error)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1c0bf0-876f-4bee-a11c-852c58df863d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Lightning (doesnt work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "81cb9049-26b9-4a7b-8fcf-1f23ab2c8493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from deepchem.models.lightning import DCLightningModule, DCLightningDatasetModule\n",
    "import pytorch_lightning as L\n",
    "\n",
    "lightning_model = DCLightningModule(model)\n",
    "train_data_module = DCLightningDatasetModule(train, model.batch_size)\n",
    "valid_data_module = DCLightningDatasetModule(val, model.batch_size)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    accelerator='gpu',  # Use GPU\n",
    "    devices=1,  # Use 1 GPU (change to more if you have multiple)\n",
    "    max_epochs=50,\n",
    "    # precision=16,  # Use mixed precision for faster training\n",
    "    callbacks=[\n",
    "        L.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            mode='min',\n",
    "            verbose=True\n",
    "        ),\n",
    "        L.callbacks.ModelCheckpoint(\n",
    "            monitor='val_loss',\n",
    "            dirpath='lightning_checkpoints/',\n",
    "            filename='pagtn-{epoch:02d}-{val_loss:.2f}',\n",
    "            save_top_k=3,\n",
    "            mode='min'\n",
    "        ),\n",
    "        L.callbacks.LearningRateMonitor(logging_interval='epoch')\n",
    "    ],\n",
    "    # logger=L.loggers.TensorBoardLogger('lightning_logs/', name='pagtn_qm9'),\n",
    "    logger=L.loggers.CSVLogger('lightning_logs/', name='pagtn_qm9'),\n",
    "    log_every_n_steps=10,\n",
    "    gradient_clip_val=0.5,  # Gradient clipping for stability\n",
    "    enable_progress_bar=True,\n",
    "    deterministic=True  # For reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c787e3-a0cf-42af-b8ac-611697fca87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Lightning training on GPU...\")\n",
    "trainer.fit(lightning_model, train_data_module, valid_data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873974fc-ceb0-4dcc-90fe-a74eb16dab4e",
   "metadata": {},
   "source": [
    "### Regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c929699c-6f9c-4b6f-a109-959994acc332",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.use_deterministic_algorithms(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d023cd-8a63-4b77-aaf3-f31bff02103a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base MAE\n",
      "Valid_mae: 3.482545019443993\n",
      "Training PagtnModel...\n",
      "Epoch #1\t\n",
      "GPU Memory allocated: 0.02 GB\n",
      "Valid_mae: 1.3255443662811253\n",
      "Epoch 0:\n",
      "  Train MAE: 1.3236, R2: 0.0001\n",
      "  Valid MAE: 1.3255, R2: 0.0001\n",
      "Epoch #2\t\n",
      "GPU Memory allocated: 0.02 GB\n"
     ]
    }
   ],
   "source": [
    "best_valid_mae = float('inf')\n",
    "patience = 20\n",
    "current_patience = 0\n",
    "training_history = []\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Base MAE\")\n",
    "valid_scores = model.evaluate(val_filtered, metrics, transformers)\n",
    "valid_mae = valid_scores['mae_score']\n",
    "print(f\"Valid_mae: {valid_mae}\")\n",
    "\n",
    "print(\"Training PagtnModel...\")\n",
    "for epoch in range(200):\n",
    "    print(f\"Epoch #{epoch + 1}\", end='\\t')\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"\\nGPU Memory allocated: {torch.cuda.memory_allocated(0)/1e9:.2f} GB\")\n",
    "    \n",
    "    loss = model.fit(train_filtered, nb_epoch=1, deterministic=False)\n",
    "    training_history.append(loss)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    valid_scores = model.evaluate(val_filtered, metrics, transformers)\n",
    "    valid_mae = valid_scores['mae_score']\n",
    "\n",
    "    print(f\"Valid_mae: {valid_mae}\")\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        train_scores = model.evaluate(train_filtered, metrics, transformers)\n",
    "        print(f\"Epoch {epoch}:\")\n",
    "        print(f\"  Train MAE: {train_scores['mae_score']:.4f}, \"\n",
    "              f\"R2: {train_scores['pearson_r2_score']:.4f}\")\n",
    "        print(f\"  Valid MAE: {valid_mae:.4f}, \"\n",
    "              f\"R2: {valid_scores['pearson_r2_score']:.4f}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if valid_mae < best_valid_mae:\n",
    "        best_valid_mae = valid_mae\n",
    "        current_patience = 0\n",
    "        # Save best model\n",
    "        # model.save()\n",
    "        torch.save(model.model.state_dict(), \"best_model_checkpoint.pth\")\n",
    "    else:\n",
    "        current_patience += 1\n",
    "        print(f\"MAE did not decrease, current patience: {current_patience}\")\n",
    "        if current_patience >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "# Load best model for evaluation\n",
    "# model.restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a39a46-5228-4b0f-afe7-70b84cd43a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f7205392-8e7d-4bec-92cc-b5e7659c8c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f382e4a-99b0-4f72-9484-f4473ec15dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
